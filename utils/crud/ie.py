import io
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Type

import pandas as pd
import streamlit as st
from sqlalchemy import inspect
from streamlit.connections import SQLConnection

from database.base import Base


class DynamicImportExport:
	"""Classe pour gÃ©rer l'import/export dynamique des donnÃ©es pour les modÃ¨les SQLAlchemy"""

	def __init__(self, connection: SQLConnection, model: Type[Base],
	             process_imported_dataframe: Optional[callable] = None):
		"""
		Initialise le gestionnaire d'import/export
		"""
		self.connection = connection
		self.model = model
		self.logger = logging.getLogger(__name__)
		self.process_imported_dataframe = process_imported_dataframe

	@staticmethod
	def get_model_columns(model_class: Type) -> Dict[str, Dict[str, Any]]:
		"""RÃ©cupÃ¨re les informations sur les colonnes d'un modÃ¨le"""
		inspector = inspect(model_class)
		columns_info = {}

		for column in inspector.columns:
			col_info = {
				'name': column.name,
				'type': str(column.type),
				'nullable': column.nullable,
				'primary_key': column.primary_key,
				'foreign_key': bool(column.foreign_keys),
				'default': column.default,
				'autoincrement': column.autoincrement
			}
			columns_info[column.name] = col_info

		return columns_info

	def export_table_data(self, filters: Optional[Dict] = None) -> pd.DataFrame:
		"""Exporte les donnÃ©es d'une table vers un DataFrame"""
		table_name = self.model.__tablename__
		try:
			if not self.model:
				raise ValueError(f"ModÃ¨le pour la table '{table_name}' non trouvÃ©")

			# Construire la requÃªte
			with self.connection.session as session:
				query = session.query(self.model)

				# Appliquer les filtres si fournis
				if filters:
					for column, value in filters.items():
						if hasattr(self.model, column) and value is not None:
							query = query.filter(getattr(self.model, column) == value)

				# ExÃ©cuter la requÃªte et convertir en DataFrame
				results = query.all()

				if not results:
					return pd.DataFrame()

				# Convertir en dictionnaire puis DataFrame
				data_list = []
				for result in results:
					row_data = {}
					for column in inspect(self.model).columns:
						value = getattr(result, column.name)
						# GÃ©rer les types spÃ©ciaux
						if isinstance(value, datetime):
							value = value.isoformat()
						elif value is None:
							value = None
						else:
							value = str(value) if not isinstance(value, (int, float, bool)) else value
						row_data[column.name] = value
					data_list.append(row_data)

				return pd.DataFrame(data_list)

		except Exception as e:
			self.logger.error(f"Erreur lors de l'export de {table_name}: {str(e)}")
			raise

	def validate_import_data(self, df: pd.DataFrame) -> Dict[str, List[str]]:
		"""Valide les donnÃ©es Ã  importer"""
		table_name = self.model.__tablename__
		if not self.model:
			return {"errors": [f"ModÃ¨le pour la table '{table_name}' non trouvÃ©"]}

		columns_info = self.get_model_columns(self.model)
		errors = []
		warnings = []

		# VÃ©rifier les colonnes obligatoires
		required_columns = [col for col, info in columns_info.items()
		                    if not info['nullable'] and not info['autoincrement']
		                    and info['default'] is None]

		missing_required = [col for col in required_columns if col not in df.columns]
		if missing_required:
			errors.append(f"Colonnes obligatoires manquantes: {', '.join(missing_required)}")

		# VÃ©rifier les colonnes inconnues
		unknown_columns = [col for col in df.columns if col not in columns_info]
		if unknown_columns:
			warnings.append(f"Colonnes inconnues (ignorÃ©es): {', '.join(unknown_columns)}")

		# VÃ©rifier les valeurs nulles dans les colonnes non-nulles
		for col in df.columns:
			if col in columns_info and not columns_info[col]['nullable']:
				null_count = df[col].isnull().sum()
				if null_count > 0:
					errors.append(f"Colonne '{col}' contient {null_count} valeurs nulles (non autorisÃ©es)")

		return {"errors": errors, "warnings": warnings}

	def import_table_data(self, df: pd.DataFrame,
	                      mode: str = "insert") -> Dict[str, Any]:
		"""
		Importe les donnÃ©es dans une table

		Args:
			df: DataFrame contenant les donnÃ©es
			mode: "insert", "update", "upsert" ou "replace"
		"""
		table_name = self.model.__tablename__
		with self.connection.session as session:
			try:
				if not self.model:
					raise ValueError(f"ModÃ¨le pour la table '{table_name}' non trouvÃ©")

				columns_info = self.get_model_columns(self.model)

				# Filtrer les colonnes connues
				valid_columns = [col for col in df.columns if col.lower() in columns_info]
				df_filtered = df[valid_columns].copy()

				success_count = 0
				error_count = 0
				errors = []

				if mode == "replace":
					# Supprimer toutes les donnÃ©es existantes
					session.query(self.model).delete()
					session.flush()

				# Traiter chaque ligne
				for index, row in df_filtered.iterrows():
					try:
						row_data = {}

						# PrÃ©parer les donnÃ©es de la ligne
						for col in valid_columns:
							value = row[col]

							# GÃ©rer les valeurs NaN
							if pd.isna(value):
								if columns_info[col]['nullable']:
									value = None
								else:
									continue  # Ignorer si non-nullable

							# Conversion de type basique
							if 'INTEGER' in str(columns_info[col]['type']).upper():
								value = int(value) if value is not None else None
							elif 'FLOAT' in str(columns_info[col]['type']).upper():
								value = float(value) if value is not None else None
							elif 'BOOLEAN' in str(columns_info[col]['type']).upper():
								value = bool(value) if value is not None else None

							row_data[col] = value

						if mode == "insert" or mode == "replace":
							# CrÃ©er une nouvelle instance
							instance = self.model(**row_data)
							session.add(instance)

						elif mode == "update" or mode == "upsert":
							# Trouver la clÃ© primaire
							pk_columns = [col for col, info in columns_info.items() if info['primary_key']]

							if not pk_columns:
								errors.append(f"Ligne {index}: Aucune clÃ© primaire trouvÃ©e pour le mode {mode}")
								error_count += 1
								continue

							# Construire le filtre de clÃ© primaire
							pk_filter = {}
							for pk_col in pk_columns:
								if pk_col in row_data:
									pk_filter[pk_col] = row_data[pk_col]

							if len(pk_filter) != len(pk_columns):
								errors.append(f"Ligne {index}: ClÃ© primaire incomplÃ¨te")
								error_count += 1
								continue

							# Chercher l'enregistrement existant
							query = session.query(self.model)
							for pk_col, pk_value in pk_filter.items():
								query = query.filter(getattr(self.model, pk_col) == pk_value)

							existing = query.first()

							if existing:
								# Mettre Ã  jour l'enregistrement existant
								for col, value in row_data.items():
									if not columns_info[col]['primary_key']:  # Ne pas modifier les clÃ©s primaires
										setattr(existing, col, value)
							elif mode == "upsert":
								# CrÃ©er un nouvel enregistrement
								instance = self.model(**row_data)
								session.add(instance)
							else:
								errors.append(f"Ligne {index}: Enregistrement non trouvÃ© pour la mise Ã  jour")
								error_count += 1
								continue

						success_count += 1

					except Exception as e:
						error_count += 1
						errors.append(f"Ligne {index}: {str(e)}")
						continue

				# Commit des changements
				session.commit()

				return {
					"success": True,
					"success_count": success_count,
					"error_count": error_count,
					"errors": errors
				}

			except Exception as e:
				session.rollback()
				self.logger.error(f"Erreur lors de l'import dans {table_name}: {str(e)}")
				return {
					"success": False,
					"success_count": 0,
					"error_count": len(df),
					"errors": [str(e)]
				}


def render_export(key_prefix: str, table_name: str, pretty_table_name: str, import_export_manager: DynamicImportExport):
	st.write("**Exporter les donnÃ©es de la table**")

	# Options d'export
	col1, col2 = st.columns(2)

	with col1:
		export_format = st.selectbox(
			"Format d'export",
			["CSV", "Excel"],
			key=f"{key_prefix}_export_format_{table_name}"
		)

	with col2:
		limit_records = st.number_input(
			"Limite d'enregistrements (0 = tous)",
			min_value=0,
			value=0,
			key=f"{key_prefix}_limit_{table_name}"
		)

	# Bouton d'export
	if st.button(f"ğŸ”½ Exporter {pretty_table_name}", key=f"{key_prefix}_export_btn_{table_name}"):
		try:
			with st.spinner("Export en cours..."):
				# RÃ©cupÃ©rer les donnÃ©es
				df = import_export_manager.export_table_data()

				if df.empty:
					st.warning("Aucune donnÃ©e Ã  exporter")
				else:
					# Appliquer la limite si spÃ©cifiÃ©e
					if limit_records > 0:
						df = df.head(limit_records)

					timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

					if export_format == "CSV":
						# Export CSV
						csv_data = df.to_csv(index=False)
						st.download_button(
							label="ğŸ“„ TÃ©lÃ©charger CSV",
							data=csv_data,
							file_name=f"{table_name}_{timestamp}.csv",
							mime="text/csv",
							key=f"{key_prefix}_download_csv_{table_name}"
						)
					else:
						# Export Excel
						excel_buffer = io.BytesIO()
						with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
							df.to_excel(writer, sheet_name=table_name, index=False)

						st.download_button(
							label="ğŸ“Š TÃ©lÃ©charger Excel",
							data=excel_buffer.getvalue(),
							file_name=f"{table_name}_{timestamp}.xlsx",
							mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
							key=f"{key_prefix}_download_excel_{table_name}"
						)

					st.success(f"âœ… Export rÃ©ussi! {len(df)} enregistrements")

					# AperÃ§u des donnÃ©es
					with st.expander("ğŸ‘ï¸ AperÃ§u des donnÃ©es exportÃ©es"):
						st.dataframe(df.head(10), use_container_width=True)

		except Exception as e:
			st.error(f"âŒ Erreur lors de l'export: {str(e)}")


def render_import(key_prefix: str, table_name: str, pretty_table_name: str, import_export_manager: DynamicImportExport):
	st.write("**Importer des donnÃ©es dans la table**")

	# Upload du fichier
	uploaded_file = st.file_uploader(
		f"Fichier pour {pretty_table_name}",
		type=['xlsx', 'xls', 'csv'],
		key=f"{key_prefix}_upload_{table_name}"
	)

	if uploaded_file is not None:
		try:
			# Lire le fichier
			if uploaded_file.name.endswith('.csv'):
				df = pd.read_csv(uploaded_file)
			else:
				df = pd.read_excel(uploaded_file)

			if import_export_manager.process_imported_dataframe:
				df = import_export_manager.process_imported_dataframe(df)

			st.success(f"âœ… Fichier lu: {len(df)} lignes, {len(df.columns)} colonnes")

			# AperÃ§u des donnÃ©es
			with st.expander("ğŸ‘ï¸ AperÃ§u des donnÃ©es Ã  importer"):
				st.dataframe(df.head(10), use_container_width=True)

			# Validation des donnÃ©es
			validation_result = import_export_manager.validate_import_data(df)

			if validation_result.get("warnings"):
				for warning in validation_result["warnings"]:
					st.warning(f"âš ï¸ {warning}")

			if validation_result.get("errors"):
				for error in validation_result["errors"]:
					st.error(f"âŒ {error}")
				can_import = False
			else:
				can_import = True

			if can_import:
				# Options d'import
				col1, col2 = st.columns(2)

				with col1:
					import_mode = st.selectbox(
						"Mode d'import",
						["insert", "update", "upsert", "replace"],
						help="""
	                            - insert: Ajouter de nouveaux enregistrements
	                            - update: Mettre Ã  jour les enregistrements existants
	                            - upsert: InsÃ©rer ou mettre Ã  jour selon l'existence
	                            - replace: Remplacer toutes les donnÃ©es de la table
	                            """,
						key=f"{key_prefix}_mode_{table_name}"
					)

				with col2:
					st.number_input(
						"Taille de lot",
						min_value=1,
						max_value=1000,
						value=100,
						key=f"{key_prefix}_batch_{table_name}"
					)

				# Confirmation pour le mode replace
				confirm_replace = True
				if import_mode == "replace":
					confirm_replace = st.checkbox(
						"âš ï¸ Je confirme vouloir remplacer toutes les donnÃ©es existantes",
						key=f"{key_prefix}_confirm_{table_name}"
					)

				# Bouton d'import
				if st.button(
						f"ğŸ”¼ Importer dans {pretty_table_name}",
						disabled=not confirm_replace,
						key=f"{key_prefix}_import_btn_{table_name}"
				):
					with st.spinner("Import en cours..."):
						result = import_export_manager.import_table_data(df, import_mode)

						if result["success"]:
							st.success(f"âœ… Import rÃ©ussi! {result['success_count']} enregistrements traitÃ©s")

							if result["error_count"] > 0:
								st.warning(f"âš ï¸ {result['error_count']} erreurs rencontrÃ©es")

								with st.expander("Voir les erreurs"):
									for error in result["errors"]:
										st.error(error)

							# Rerun pour actualiser les donnÃ©es
							st.rerun()
						else:
							st.error(f"âŒ Import Ã©chouÃ©: {result['error_count']} erreurs")
							for error in result["errors"]:
								st.error(error)

		except Exception as e:
			st.error(f"âŒ Erreur lors de la lecture du fichier: {str(e)}")

def render_import_export_interface(import_export_manager: DynamicImportExport,
                                   key_prefix: str = "", can_import: bool = True, can_export: bool = True):
	"""
	Affiche l'interface Streamlit pour l'import/export d'une table

	Args:
		import_export_manager: Instance de DynamicImportExport
		key_prefix: PrÃ©fixe pour les clÃ©s Streamlit (Ã©viter les conflits)
	"""
	table_name = import_export_manager.model.__tablename__
	pretty_table_name = import_export_manager.model.__crud_tablename__

	if not can_import and not can_export:
		st.warning("Aucune action disponible pour cette table")
		return
	elif not can_import:
		st.subheader(f"ğŸ“Š Export - {pretty_table_name}")
		render_export(key_prefix, table_name, pretty_table_name)
	elif not can_export:
		st.subheader(f"ğŸ“Š Import - {pretty_table_name}")
		render_import(key_prefix, table_name, pretty_table_name, import_export_manager)
	else:
		st.subheader(f"ğŸ“Š Import/Export - {pretty_table_name}")
		# Onglets pour sÃ©parer import et export
		tab_export, tab_import = st.tabs(["ğŸ“¤ Export", "ğŸ“¥ Import"])
		with tab_export:
			render_export(key_prefix, table_name, pretty_table_name, import_export_manager)
		with tab_import:
			render_import(key_prefix, table_name, pretty_table_name, import_export_manager)
